Brief Theory of Convolutional Neural Network
======================================


Convolutional Neural Network(CNN) is the most popular branch of Deep Learning. Unlike other neural network, not all the layers in CNN are fully connected. The basic structured is described as follows.

\subsection{Basic structure}

The basic structure of CNN can be seen in Figure XX.

\paragraph{Convolutional Layer}
The most difference between normal neural network and CNN is the convolutional layer, which use kernel map or filter to extract the features from raw data. Figure xx gives the simple demonstration of how filter works. 

\paragraph{Pooling Layer}
Sometimes, to reduce the spatial size of input data, pooling 

\paragraph{Fully Connected Layer}

Fully connected layer works just like other neural network. 

\subsection{Activation Functions}

Normally, the activation function is applied to the output of each layer. The reason is introduce nonlinearity to the network, and make it possible to approximate any nonlinear function.

The most commen used activation functions include sigmoid, Relu and softmax. The details description is as follows.


\paragraph{ReLu (rectified linear unit)/leaky ReLu}
